{"tagline":"Simple Management System for Hadoop MapReduce Job.","note":"Don't delete this file! It's used internally to help with page regeneration.","name":"Huahin Manager","body":"## Huahin Manager\r\nHuahin Manager is Simple Management System for Hadoop MapReduce Job.\r\nHuahin can get a list of MapReduce jobs, get status, do a kill for the job, and Job queue management.\r\n\r\nHuahin Manager is distributed under Apache License 2.0.\r\n\r\n### Download\r\n[Huahin Manager 0.2.1 for for Apache Hadoop 2.0.2-alpha](http://huahin-framework.googlecode.com/files/huahin-manager-a-0.2.1.tar.gz)\r\n<br/>\r\n[Huahin Manager 0.2.1 for CDH4](http://huahin-framework.googlecode.com/files/huahin-manager-c-0.2.0.tar.gz)\r\n<br/>\r\n[Huahin Manager 0.1.4 for Apache Hadoop 1.0.4](http://huahin-framework.googlecode.com/files/huahin-manager-a-0.1.4.tar.gz)\r\n<br/>\r\n[Huahin Manager 0.1.4 for CDH3](http://huahin-framework.googlecode.com/files/huahin-manager-c-0.1.4.tar.gz)\r\n<br/>\r\n\r\n### Requirements\r\n```\r\nJava 6+\r\n```\r\n<br/>\r\n\r\n### Install Huahin Manager\r\n```\r\n~ $ tar xzf huahin-manager-x.x.x.tar.gz\r\n```\r\n<br/>\r\n\r\n### Configure Huahin Manager\r\nEdit the huahin-manager-x.x.x/conf/huahinManager.properties file and set mapred.job.tracker property to the JobTracker URI,\r\nset fs.default.name property to the NameNode URI, and set job.queue.limit property to the job queue limit.\r\njob queue limit is 0, does not manage the queue.\r\n<br/>\r\nFor 0.1.X example:\r\n\r\n```\r\nmapred.job.tracker=localhost:9001\r\nfs.default.name=hdfs://localhost:9000\r\nhiveserver=localhost:10000 # option\r\njob.queue.limit=2\r\n```\r\n\r\nFor 0.2.X example:\r\n\r\n```\r\nyarn.resourcemanager.address=localhost:8032\r\nmapreduce.jobhistory.address=localhost:10020\r\nfs.defaultFS=hdfs://localhost:8020\r\nyarn.resourcemanager.webapp.address=localhost:8088\r\nyarn.nodemanager.webapp.address=localhost:8042\r\nyarn.web-proxy.address=localhost:8100\r\nmapreduce.jobhistory.webapp.address=localhost:19888\r\n# option: if you do not set it will be the default.\r\nyarn.application.classpath=$HADOOP_CONF_DIR,$HADOOP_COMMON_HOME/*,...\r\n# option\r\nhiveserver=localhost:10000\r\n# option\r\nhiveserver.version=2\r\njob.queue.limit=2\r\n```\r\n\r\nWhen you change the boot port, edit the huahin-manager-x.x.x/conf/port file.\r\n<br/>\r\n\r\n### Start/Stop Huahin Manager\r\nTo start/stop Huahin Manager use Huahin Manager's bin/manager script. For example:\r\n\r\n```\r\n$ bin/manager start\r\n```\r\n<br/>\r\n\r\n### Test Huahin Manager is working\r\n```\r\n~ $ curl -X GET \"http://<HOSTNAME>:9010/job/list\"\r\n[\r\n  {\r\n    \"jobid\": \"job_201205111223_0001\",\r\n    \"mapComplete\": \"100.0%\",\r\n    \"name\": \"JOB_EBCF7626A41F34B4C7276DB2B152336F\",\r\n    \"priority\": \"NORMAL\",\r\n    \"reduceComplete\": \"100.0%\",\r\n    \"schedulingInfo\": \"NA\",\r\n    \"startTime\": \"Fri May 11 12:25:18 JST 2012\",\r\n    \"state\": \"SUCCEEDED\",\r\n    \"user\": \"huahin\"\r\n  }\r\n]\r\n```\r\n<br/>\r\n\r\n### Huahin Manager on the Amazon Elastic MapReduce\r\nHuahin Manager will be able to run on Amazon Elastic MapReduce by setting the bootstrap.\r\n\r\n##### Setup of Security Group\r\nSet the your IP address and port(9010) for the Huahin Manager to the Security Group(ElasticMapReduce-master).\r\nFor example:\r\n* Port range: 9010\r\n* Source: 1.1.1.1/32\r\n\r\n##### Starting The Amazon Elastic MapReduce.\r\nReferences bootstrap is as follows:\r\n```\r\ns3://huahin/manager/configure\r\n```\r\n\r\nThe following is an example run using Ruby Client(elastic-mapreduce).\r\n```\r\n~ $ elastic-mapreduce --create --alive \\\r\n--master-instance-type m1.large --slave-instance-type m1.small \\\r\n--num-instances 2 \\\r\n--bootstrap-action s3://huahin/manager/configure\r\n```\r\n\r\nAfter checking the Public DNS Name for the Master Node, you can use the API of the Huahin Manager.\r\n```\r\n~ $ elastic-mapreduce --describe --jobflow j-XXXXXXXXX\r\n{\r\n  \"JobFlows\": [\r\n    {\r\n      ...\r\n      \"Instances\": {\r\n        ...\r\n        \"MasterPublicDnsName\": \"ec2-1-2-3-4.compute-1.amazonaws.com\",\r\n        ...\r\n      }\r\n    }\r\n  ]\r\n}\r\n~ $ curl -X GET \"http://ec2-1-2-3-4.compute-1.amazonaws.com:9010/job/list\"\r\n```\r\n\r\n<br/>\r\n\r\n### Huahin Manager REST Job APIs\r\nGet all job list. For example:\r\n```\r\n~ $ curl -X GET \"http://<HOSTNAME>:9010/job/list\"\r\n```\r\n<br/>\r\n\r\nGet failed job list. For example:\r\n```\r\n~ $ curl -X GET \"http://<HOSTNAME>:9010/job/list/failed\"\r\n```\r\n<br/>\r\n\r\nGet killed job list. For example:\r\n```\r\n~ $ curl -X GET \"http://<HOSTNAME>:9010/job/list/killed\"\r\n```\r\n<br/>\r\n\r\nGet prep job list. For example:\r\n```\r\n~ $ curl -X GET \"http://<HOSTNAME>:9010/job/list/prep\"\r\n```\r\n<br/>\r\n\r\nGet running job list. For example:\r\n```\r\n~ $ curl -X GET \"http://<HOSTNAME>:9010/job/list/running\"\r\n```\r\n<br/>\r\n\r\nGet succeeded job list. For example:\r\n```\r\n~ $ curl -X GET \"http://<HOSTNAME>:9010/job/list/succeeded\"\r\n```\r\n<br/>\r\n\r\nGet job status. {JOBID} specifies the jobid.\r\n```\r\n~ $ curl -X GET \"http://<HOSTNAME>:9010/job/status/{JOBID}\"\r\n```\r\nFor example:\r\n```\r\n~ $ curl -X GET \"http://<HOSTNAME>:9010/job/status/job_201205111223_0001\"\r\n```\r\n<br/>\r\n\r\nGet job detail. {JOBID} specifies the jobid.\r\n```\r\n~ $ curl -X GET \"http://<HOSTNAME>:9010/job/detail/{JOBID}\"\r\n```\r\nFor example:\r\n```\r\n~ $ curl -X GET \"http://<HOSTNAME>:9010/job/detail/job_201205111223_0001\"\r\n```\r\n<br/>\r\n\r\nRegister job.<br/>\r\nJAR=@{JAR_FILE} specifies the run jar file.\r\nARGUMENTS specifies the JSON. {CLASS} specifies the run class. arguments:{ARGS} specifies the run arguments array.\r\n```\r\n~ $ curl -X POST \"http://<HOSTNAME>:9010/job/register -F JAR=@{JAR_FILE} -F ARGUMENTS='{\"class\":\"{CLASS}\",\"arguments\":[\"{ARGS}\",\"{ARGS}\"]}'\r\n```\r\nFor example:\r\n```\r\n~ $ curl -X POST \"http://<HOSTNAME>:9010/job/register -F JAR=@mapreduce.jar \\\r\n-F ARGUMENTS='{\"class\":\"examples.WordCount\",\"arguments\":[\"/user/huahin/input\",\"/user/huahin/output\"]}'\r\n```\r\n<br/>\r\n\r\nRegister Hive job<br/>\r\nBecause they are executed in the queue, the return value must be a table or HDFS.\r\nARGUMENTS specifies the JSON. {script} specifies the hive query.\r\n```\r\n~ $ curl -X POST \"http://<HOSTNAME>:9010/job/hive/register -F ARGUMENTS='{\"script\":\"{script}\"}'\r\n```\r\nFor example:\r\n```\r\n~ $ curl -X POST \"http://<HOSTNAME>:9010/job/hive/register \\\r\n-F ARGUMENTS='{\"script\":\"insert overwrite directory '\\''/tmp/out'\\'' select word, count(word) as cnt from words group by word\"}'\r\n```\r\n<br/>\r\n\r\nRegister Pig job<br/>\r\nBecause they are executed in the queue, the return value must be a table or HDFS.\r\nARGUMENTS specifies the JSON. {script} specifies the Pig Latin.\r\n```\r\n~ $ curl -X POST \"http://<HOSTNAME>:9010/job/pig/register -F ARGUMENTS='{\"script\":\"{script}\"}'\r\n```\r\nFor example:\r\n```\r\n~ $ curl -X POST \"http://<HOSTNAME>:9010/job/pig/register \\\r\n-F ARGUMENTS='{\"script\":\"a = load '\\''/user/huahin/input'\\'' as (text:chararray);b = foreach a generate flatten(TOKENIZE(text)) as word;c = group b by word;d = foreach c generate group as word, COUNT(b) as count;store d into '\\''/tmp/out'\\'';\"}'\r\n```\r\n<br/>\r\n\r\nKill job for ID. {JOBID} specifies the job ID.\r\n```\r\n~ $ curl -X DELETE \"http://<HOSTNAME>:9010/job/kill/id/{JOBID}\"\r\n```\r\nFor example:\r\n```\r\n~ $ curl -X DELETE \"http://<HOSTNAME>:9010/job/kill/id/job_201205111223_0001\"\r\n```\r\n<br/>\r\n\r\nKill job for job name. {JOBNAME} specifies the job name.\r\n```\r\n~ $ curl -X DELETE \"http://<HOSTNAME>:9010/job/kill/name/{JOBNAME}\"\r\n```\r\nFor example:\r\n```\r\n~ $ curl -X DELETE \"http://<HOSTNAME>:9010/job/kill/name/WORD_COUNT_JOB\"\r\n```\r\n<br/>\r\n\r\n### Huahin Manager REST queue APIs\r\nGet all queue list. For example:\r\n```\r\n~ $ curl -X GET \"http://<HOSTNAME>:9010/queue/list\"\r\n```\r\n<br/>\r\n\r\nGet run queue statuses. For example:\r\n```\r\n~ $ curl -X GET \"http://<HOSTNAME>:9010/queue/statuses\"\r\n```\r\n<br/>\r\n\r\nKill queue for ID. {QUEUEID} specifies the queue ID.\r\n```\r\n~ $ curl -X DELETE \"http://<HOSTNAME>:9010/queue/kill/{QUEUEID}\"\r\n```\r\nFor example:\r\n```\r\n~ $ curl -X DELETE \"http://<HOSTNAME>:9010/queue/kill/Q_20120608180129594\"\r\n```\r\n<br/>\r\n\r\n### Huahin Manager REST Hive APIs\r\nExecution of the query does not return value<br/>\r\nARGUMENTS specifies the JSON. {query} specifies the hive query.\r\n```\r\n~ $ curl -X POST \"http://<HOSTNAME>:9010/hive/execute -F ARGUMENTS='{\"query\":\"{query}\"}'\r\n```\r\nFor example:\r\n```\r\n~ $ curl -X POST \"http://<HOSTNAME>:9010/hive/execute \\\r\n-F ARGUMENTS='{\"query\":\"create table foo(bar string)\"}'\r\n```\r\n<br/>\r\n\r\nQuery execution with return value<br/>\r\nThe return value is returned in the stream.\r\nARGUMENTS specifies the JSON. {query} specifies the hive query.\r\n```\r\n~ $ curl -X POST \"http://<HOSTNAME>:9010/hive/executeQuery -F ARGUMENTS='{\"query\":\"{query}\"}'\r\n```\r\nFor example:\r\n```\r\n~ $ curl -X POST \"http://<HOSTNAME>:9010/hive/executeQuery \\\r\n-F ARGUMENTS='{\"query\":\"select word, count(word) as cnt from words group by word\"}'\r\n```\r\n<br/>\r\n\r\n### Huahin Manager REST Pig APIs\r\nExecution of the dump<br/>\r\nARGUMENTS specifies the JSON. {variable} is that specifies the dump. {query} specifies the Pig Latin.\r\n```\r\n~ $ curl -X POST \"http://<HOSTNAME>:9010/pig/dump -F ARGUMENTS='{\"dump\":\"{variable}\",\"query\":\"{query}\"}'\r\n```\r\nFor example:\r\n```\r\n~ $ curl -X POST \"http://<HOSTNAME>:9010/pig/dump \\\r\n-F ARGUMENTS='{\"dump\":\"d\",\"query\":\"a = load '\\''/user/huahin/input'\\'' as (text:chararray);b = foreach a generate flatten(TOKENIZE(text)) as word;c = group b by word;d = foreach c generate group as word, COUNT(b) as count;store d into '\\''/tmp/out'\\'';\"}'\r\n```\r\n<br/>\r\n\r\nExecution of the store<br/>\r\nThe return value is returned in the stream.\r\nARGUMENTS specifies the JSON. {query} specifies the Pig Latin.\r\n```\r\n~ $ curl -X POST \"http://<HOSTNAME>:9010/pig/store -F ARGUMENTS='{\"query\":\"{query}\"}'\r\n```\r\nFor example:\r\n```\r\n~ $ curl -X POST \"http://<HOSTNAME>:9010/pig/store \\\r\n-F ARGUMENTS='{\"query\":\"a = load '\\''/user/huahin/input'\\'' as (text:chararray);b = foreach a generate flatten(TOKENIZE(text)) as word;c = group b by word;d = foreach c generate group as word, COUNT(b) as count;store d into '\\''/tmp/out'\\'';\"}'\r\n```\r\n<br/>\r\n\r\n### For 0.2.X\r\n### Huahin Manager REST YARN APIs\r\n[http://hadoop.apache.org/docs/r2.0.2-alpha/hadoop-yarn/hadoop-yarn-site/WebServicesIntro.html](http://hadoop.apache.org/docs/r2.0.2-alpha/hadoop-yarn/hadoop-yarn-site/WebServicesIntro.html)\r\n\r\nResourceManager REST API's\r\nFor example:\r\n```\r\n~ $ curl -X GET \"http://<HOSTNAME>:9010/api/rm/ws/v1/cluster/info\"\r\n```\r\n<br/>\r\n\r\nNodeManager REST API's\r\nFor example:\r\n```\r\n~ $ curl -X GET \"http://<HOSTNAME>:9010/api/nm/ws/v1/node/info\"\r\n```\r\n<br/>\r\n\r\nMapReduce Application Master REST API's\r\nFor example:\r\n```\r\n~ $ curl -X GET \"http://<HOSTNAME>:9010/api/proxy/{appid}/ws/v1/mapreduce/info\"\r\n```\r\n<br/>\r\n\r\nHistory Server REST API's\r\nFor example:\r\n```\r\n~ $ curl -X GET \"http://<HOSTNAME>:9010/api/history/ws/v1/history/info\"\r\n```\r\n<br/>\r\n\r\n### Huahin Manager REST Application APIs\r\nGet all application list\r\nFor example:\r\n```\r\n~ $ curl -X GET \"http://<HOSTNAME>:9010/application/list\"\r\n```\r\n<br/>\r\n\r\nGet cluster info\r\nFor example:\r\n```\r\n~ $ curl -X GET \"http://<HOSTNAME>:9010/application/cluster\"\r\n```\r\n<br/>\r\n\r\nKill application for ID\r\n{appid} specifies the application ID.\r\n```\r\n~ $ curl -X DELETE \"http://<HOSTNAME>:9010/application/kill/{appid}\"\r\n```\r\nFor example:\r\n```\r\n~ $ curl -X DELETE \"http://<HOSTNAME>:9010/application/kill/application_1326232085508_0003\"\r\n```\r\n<br/>\r\n\r\n### Support or Contact\r\nContact huahin-framework@googlegroups.com and weâ€™ll help you sort it out.","google":"UA-32923864-1"}